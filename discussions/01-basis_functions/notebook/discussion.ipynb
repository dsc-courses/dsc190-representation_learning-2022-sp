{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to Discussion 01. In this discussion, we'll get more practice with linear predictors and basis functions.\n",
    "\n",
    "Some of the problems below can either be calculated \"by hand\" or with code. You can use either approach unless stated otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Linear Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 01**. Suppose $H$ is a linear prediction function of the form discussed in lecture with weights $w_0 = 5, w_1 = -2, w_2 = 4, w_3 = -5$. Let $\\vec x = (1,2,3)^T$. What is $H(\\vec x)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 02.** Below is a data set of ten unaugmented feature vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.normal(0, 1, (10, 3))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have training a linear prediction function and obtained the following weight vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([1, -2, 3, -4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `w[0]` is the bias term, `w[1]` is the weight of the first feature (the first column of `X`), etc. Compute the array of predictions -- it should contain ten elements, one for each row of `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 03**. Suppose you have trained a linear prediction function to predict the price of a house given three features:\n",
    "\n",
    "1. Size in square feet\n",
    "2. Number of bathrooms\n",
    "3. Number of holes in the roof\n",
    "\n",
    "Assuming that your prediction function makes good predictions, what do you expect the *sign* of the weights $w_1, w_2,$ and $w_3$ to be? To denote a positive weight, set a variable to 1; to denote a negative weight, set the variable to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 04**. Suppose you build a regression model to predict the number of hours of TV that\n",
    "a person watches in a day given their age, income, etc. In your training set,\n",
    "the actual number of hours each person watched is 8, 3, 1, 10, and 5. Your\n",
    "model predicts 9, 2, 0, 9, and 3. What is the mean squared error of your\n",
    "predictions?\n",
    "\n",
    "Fun fact: in a typical, non-quarantine day, the average American watches\n",
    "between 4 to 5 hours of TV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 05**. The array `X_apt` is a data matrix containing the number of bedrooms and number of bathrooms for five San Diego apartments. The array `y_apt` contains the price of rent for each apartment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_apt = np.array([\n",
    "    [2, 3],\n",
    "    [4, 4],\n",
    "    [5, 3],\n",
    "    [3, 2],\n",
    "    [3, 1]\n",
    "])\n",
    "\n",
    "y_apt = np.array([2000, 3000, 4000, 1750, 1650])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using numpy only, train a linear prediction function of the form $H(\\vec x) = w_0 + w_1 x_1 + w_2 x_2$ to predict the apartment price from the number of bedrooms and bathrooms (where $x_1$ is number of bedrooms and $x_2$ is number of bathrooms. Store the learned weights in the array `w_apt`.\n",
    "\n",
    "You can use whatever numpy functions you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 06.** Complete the function below so that it takes in an array of predictions and a target array of correct answers (1 or -1) and returns the expected perceptron loss. Note that the prediction is the output of the prediction function, and is a real number (is is not necessarily 1 or -1, but can be, for example, 0.3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_perceptron_loss(predictions, targets):\n",
    "    \"\"\"Compute the expected perceptron loss.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : np.ndarray\n",
    "        An array of predictions as output by a prediction function.\n",
    "    targets : np.ndarray\n",
    "        An array of \"right answers\".\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The expected perceptron loss.\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    >>> expected_perceptron_loss(\n",
    "        predictions=np.array([.1, .4, -.3, .6]), \n",
    "        targets=np.array([1, -1, 1, 1])\n",
    "        )\n",
    "    0.175\n",
    "    \n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 1 ##\n",
    "expected_perceptron_loss(\n",
    "        predictions=np.array([.1, .4, -.3, .6]), \n",
    "        targets=np.array([1, -1, 1, 1])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 2 ##\n",
    "expected_perceptron_loss(\n",
    "        predictions=np.array([.1, .4, -.3, .6, -2, -.3, 5, 3.1]), \n",
    "        targets=np.array([1, -1, 1, 1, -1, -1, 1, 1])\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 07**. The figure below shows a data set consisting of 200 points from two classes.\n",
    "\n",
    "<img width=50% src=\"fig/data.png\">\n",
    "\n",
    "Suppose this data set is transformed to a new representation using basis functions $\\phi_1$ and $\\phi_2$. The result is show below:\n",
    "\n",
    "<img width=50% src=\"fig/data_transformed.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following options gives the basis functions that were used?\n",
    "\n",
    "- a) $\\phi_1(x_1, x_2) = |x_1|, \\quad \\phi_2(x_1, x_2) = |x_2|$\n",
    "- b) $\\phi_1(x_1, x_2) = |x_1 - x_2|, \\quad \\phi_2(x_1, x_2) = |x_1 + x_2|$\n",
    "- c) $\\phi_1(x_1, x_2) = x_1 \\cdot x_2, \\quad \\phi_2(x_1, x_2) = x_1 + x_2$\n",
    "- d) $\\phi_1(x_1, x_2) = x_1^2 + x_2^2, \\quad \\phi_2(x_1, x_2) = -x_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 08**. The *training accuracy* of a classifier is the proportion of predictions it gets correct on the training set. Complete the code below (using numpy only) so that it returns the training accuracy when given as input an array containing the predictions made by a prediction function on the training set and an array of the correct labels (1 or -1). Note that the output of the predictor may be an arbitrary real number, like 0.3, in which case the $\\operatorname{sign}()$ function should be used to \"convert\" it to $\\{-1, 1\\}$.\n",
    "\n",
    "If a prediction is identically zero, you may assign it to whichever class you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, correct_labels):\n",
    "    \"\"\"Computes the accuracy of predictions made by a classifier.\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> accuracy([-.3, .2, .4, -.5], [-1, 1, 1, 1])\n",
    "    0.75\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 1 ##\n",
    "accuracy([-.3, .2, .4, -.5], [-1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 2 ##\n",
    "accuracy([-.3, .2, .4, -.5, -1, -5, .1, .3, .4, .6], [-1, 1, 1, 1, -1, 1, -1, 1, 1, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Basis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will get more practice with basis functions. Specifically, we'll see how they can be used for regression.\n",
    "\n",
    "Let's start by remembering how to perform linear regression by minimizing expected square loss. Here is a data set with a linear trend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(0, 10, 100)\n",
    "y = 3 * x + 5 + np.random.normal(0, 7, 100)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 01**. Fit a line of the form $h(x) = w_0 + w_1(x)$ to the data above by minimizing the expected square loss (mean squared error). Plot your line to check that it is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 02**. This works if the trend is linear, but what if the trend is not linear in $x$? One of the things we can do is use different basis functions. Here is a new data set that is very non-linear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.sin(np.pi/3 * x + .5) + np.random.normal(0, .3, 100)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a function of the form $h(x) = w_0 + w_1 x + w_2 x^2 + w_3 x^3 + w_4 x^4 + w_5 x^5$ to this data by minimizing the expected square loss. Plot your prediction function to check that it is reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 03**. Consider the data set below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X_moons, y_moons = sklearn.datasets.make_moons(200, noise=.1)\n",
    "y_moons = (y_moons - .5) * 2\n",
    "\n",
    "plt.scatter(*X_moons.T, c=y_moons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `X_moons` represents a training set of points in $\\mathbb R^2$, containing one data point per row. `y_moons` contains the label of each training point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design four basis functions, $\\varphi_1, \\ldots, \\varphi_4$ for transforming this data into a new representation in $\\mathbb R^4$ where binary classification becomes \"easy\". Your functions should take in the entire data matrix, `X`, and return an array containing the new feature for each training point.\n",
    "\n",
    "Your basis functions will be evaluated by training a least squares classifier on the augmented new features. To receive full credit, your new representation should be good enough that the classifier has a training accuracy of at least 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINISHED #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
