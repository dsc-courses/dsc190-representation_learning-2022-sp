{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion 07\n",
    "\n",
    "### Neural Networks and Function Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to Discussion 07.\n",
    "\n",
    "We often think of neural networks in the context of classification, but they can be used for non-linear regression, too. In fact, as we saw in lecture, neural networks are *universal function approximators*; they can approximate any (reasonably well-behaved) function to an arbitrary degree of precision, provided that the network has a sufficient number of hidden neurons with a suitable, non-linear activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ocean Temperatures\n",
    "\n",
    "The data set loaded below contains the ocean temperature measured in La Jolla on every day since August 1916. To reduce noise, we'll take the rolling mean with a window of 24 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = pd.read_csv('sea_temp.csv').groupby(['YEAR', 'MONTH']).mean()['SURFACE_TEMP']\n",
    "temperatures = temperatures.rolling(24).mean().dropna().values\n",
    "\n",
    "plt.plot(temperatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a deep neural network to approximate this function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**. What activation function is the best choice for the output layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Which activation function is a good choice for the hidden layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** What loss function should be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** Train a neural network with no hidden layer and using a linear activation function for the output layer and the mean squared error as the cost function. For the predictor (x) variable, use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, len(temperatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, temperatures)\n",
    "plt.plot(x, model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**. True or false. This model is exactly the same as the least squares regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** Train a neural network with one hidden layer and 10 neurons in the hidden layer. Use a ReLU activation in the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, temperatures)\n",
    "plt.plot(x, model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**. Chances are your prediction function looks linear, despite using a non-linear activation function in the hidden layer. Why do you think this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.** Train a deep NN with three hidden layers, each with 20 nodes, using the ReLU as the hidden layers' activation function. Try repeating the training several times to see how much your results vary. Why do they vary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, temperatures)\n",
    "plt.plot(x, model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9.** Train a deep NN with three hidden layers and 10 neurons in each hidden layer. However, now use the sigmoid as the hidden layer activation function. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, temperatures)\n",
    "plt.plot(x, model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic\n",
    "\n",
    "Since neural networks are universal approximators, we can train a neural network to do simple things, like multiply two numbers.\n",
    "\n",
    "Is this useful? Not really. But it is fun to see a NN learn its time tables.\n",
    "\n",
    "**Question 10.** The data below can be used as a training set to teach a deep NN to multiply numbers. `X` contains 2000 pairs of numbers between 0 and 5, and `y` contains the product of each pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(0, 5, size=(2000, 2))\n",
    "y = np.prod(X, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design and train a deep network that is able to predict the product of two numbers given as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_1 = 3\n",
    "test_x_2 = 2\n",
    "product = float(model(np.array([[test_x_1, test_x_2]])))\n",
    "product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10**. Train a NN to compute the maximum of two numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(0, 5, size=(2000, 2))\n",
    "y = np.max(X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_1 = 2\n",
    "test_x_2 = 4\n",
    "larger = float(model(np.array([[test_x_1, test_x_2]])))\n",
    "larger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.** Train a NN to compute the remainder of its input when divided by two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(0, 6, size=(2000, 1))\n",
    "y = X % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = 3.8\n",
    "product = float(model(np.array([[test_x]])))\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linspace(0, 6, 100)\n",
    "yy = np.asarray(model(xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
