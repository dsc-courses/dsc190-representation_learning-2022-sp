{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion 02\n",
    "\n",
    "## k-means and RBF Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to Discussion 02. In this discussion, we'll get more practice with k-means and radial basis functions for classification in the context of image recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will download the MNIST digit dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [[ ! -e \"mnist.npz\" ]]; then\n",
    "    wget 'https://f000.backblazeb2.com/file/jeldridge-data/mnist.npz'\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = np.load('mnist.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 01. Let's give ourselves the problem of predicting whether a given image is a three or not a three. Note that this is harder than the problem of, e.g., predicting 3 vs. 7, because all of the digits will be included in the data set.\n",
    "\n",
    "First, let's curate a training and test set. We'll balance it so that there are equally as many threes as non-threes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(features, labels):\n",
    "    threes = features[labels == 3]\n",
    "    non_threes = features[labels != 3]\n",
    "    ix = np.random.choice(len(non_threes), size=len(threes))\n",
    "    \n",
    "    X = np.vstack((threes, non_threes[ix]))\n",
    "    y = np.concatenate([\n",
    "        np.ones(len(threes)),\n",
    "        -np.ones(len(threes))\n",
    "    ])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = retrieve_data(mnist['train'].T, mnist['train_labels'].flat)\n",
    "X_test, y_test = retrieve_data(mnist['test'].T, mnist['test_labels'].flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a helpful function for visualizing an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_digit(v):\n",
    "    plt.imshow(v.reshape((28, -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_digit(X_train[7000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, here's a helper function to augment a data matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(X):\n",
    "    return np.column_stack((\n",
    "        np.ones(len(X)),\n",
    "        X\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing 28x28 pixel values in numerical form\n",
    "n = 7000\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        print(f'{X_train[n][28*i+j]:03}', end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 01.** Let's warm up by just trying a simple least squares classifier. What is the test accuracy of a least squares classifier trained on this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 02**. Perform k-means clustering and find 100 cluster centers in the training data. Plot a few of the cluster centers using `show_digit` to see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize first 10 centers\n",
    "for i in range(10):\n",
    "    show_digit(kmeans.cluster_centers_[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 03**. Below is a function which makes a Gaussian RBF given a center $\\mu$ and a value of $\\sigma$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rbf(mu, sigma):\n",
    "    def rbf(x):\n",
    "        return np.exp(-np.linalg.norm(x - mu, axis=1)**2 / sigma**2)\n",
    "    return rbf\n",
    "\n",
    "def rbf_feature(x, mu, sigma):\n",
    "    return np.exp(-np.linalg.norm(x - mu, axis=1)**2 / sigma**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, the function that is created will take in an entire data matrix, $X$, and return an array of the new feature for each data point.\n",
    "\n",
    "Using the k-means cluster centers, create an $n \\times 100$ array `X_phi_train` containing the new RBF features. Choose $\\sigma$ to be something you think is reasonable -- use the same $\\sigma$ for each RBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 04**. Following the same procedure, create the array `X_phi_test` which contains the features for the test data mapped to the same representation using the RBFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_phi_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 05**. What is the test accuracy of a least squares classifier training on your new features?\n",
    "\n",
    "*Hint*: You should be able to do better than the least squares classifier we trained before, but *only* if you choose $\\sigma$ correctly. Try a few different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra Question**. In practice, we don't choose $\\sigma$ by hand. Instead, we use a separate *validation* data set to test the accuracy obtained by using a variety of $\\sigma$ and keep the one that returns the best performance. Note that we shouldn't pick the $\\sigma$ that gives us the best result on the test set, because that is cheating!\n",
    "\n",
    "The code below splits our training set into a new training set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = sklearn.model_selection.train_test_split(\n",
    "    X_train, y_train, test_size=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a value of $\\sigma$ which gives the best accuracy on the validation set by looping over possible $\\sigma$ within a reasonable range of possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 02**. Consider the data set below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "np.random.seed(42)\n",
    "X_moons, y_moons = sklearn.datasets.make_moons(200, noise=.1)\n",
    "y_moons = (y_moons - .5) * 2\n",
    "\n",
    "plt.scatter(*X_moons.T, c=y_moons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `X_moons` represents a training set of points in $\\mathbb R^2$, containing one data point per row. `y_moons` contains the label of each training point.\n",
    "\n",
    "Design four basis functions, $\\varphi_1, \\ldots, \\varphi_4$ for transforming this data into a new representation in $\\mathbb R^4$ where binary classification becomes \"easy\". Your functions should take in the entire data matrix, `X`, and return an array containing the new feature for each training point.\n",
    "\n",
    "Your basis functions will be evaluated by training a least squares classifier on the augmented new features. To receive full credit, your new representation should be good enough that the classifier has a training accuracy of at least 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
