{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion 02\n",
    "\n",
    "## k-means and RBF Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to Discussion 02. In this discussion, we'll get more practice with k-means and radial basis functions for classification in the context of image recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will download the MNIST digit dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [[ ! -e \"mnist.npz\" ]]; then\n",
    "    wget 'https://f000.backblazeb2.com/file/jeldridge-data/mnist.npz'\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = np.load('mnist.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 01. Let's give ourselves the problem of predicting whether a given image is a three or not a three. Note that this is harder than the problem of, e.g., predicting 3 vs. 7, because all of the digits will be included in the data set.\n",
    "\n",
    "First, let's curate a training and test set. We'll balance it so that there are equally as many threes as non-threes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(features, labels):\n",
    "    threes = features[labels == 3]\n",
    "    non_threes = features[labels != 3]\n",
    "    ix = np.random.choice(len(non_threes), size=len(threes))\n",
    "    \n",
    "    X = np.vstack((threes, non_threes[ix]))\n",
    "    y = np.concatenate([\n",
    "        np.ones(len(threes)),\n",
    "        -np.ones(len(threes))\n",
    "    ])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = retrieve_data(mnist['train'].T, mnist['train_labels'].flat)\n",
    "X_test, y_test = retrieve_data(mnist['test'].T, mnist['test_labels'].flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a helpful function for visualizing an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_digit(v):\n",
    "    plt.imshow(v.reshape((28, -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_digit(X_train[7000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, here's a helper function to augment a data matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(X):\n",
    "    return np.column_stack((\n",
    "        np.ones(len(X)),\n",
    "        X\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 000 000 075 180 255 223 210 022 000 000 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 006 152 252 254 254 254 254 245 181 027 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 013 174 254 254 254 228 204 243 254 254 159 005 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 067 254 254 244 134 030 000 031 041 212 254 022 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 039 240 246 041 000 000 000 000 000 169 254 022 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 026 045 000 000 000 000 000 007 232 254 022 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 006 179 254 178 007 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 035 210 254 254 073 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 000 000 000 000 099 229 254 253 108 001 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 000 000 013 148 250 254 219 080 000 000 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 000 011 157 254 254 185 031 000 000 000 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 004 156 254 254 159 026 000 000 000 000 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 018 185 254 254 145 009 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 171 254 254 119 006 000 000 000 000 000 000 065 084 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 059 252 251 157 002 000 000 000 000 000 045 177 250 235 030 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 207 254 194 000 000 000 000 026 123 207 246 254 254 254 049 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 043 248 254 142 129 129 213 219 235 254 254 254 254 231 153 007 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 050 254 254 254 254 254 254 254 254 252 225 137 083 022 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 030 238 254 254 254 254 254 226 109 058 000 000 000 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 121 254 254 192 077 076 009 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
      "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n"
     ]
    }
   ],
   "source": [
    "# visualizing 28x28 pixel values in numerical form\n",
    "n = 7000\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        print(f'{X_train[n][28*i+j]:03}', end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 01.** Let's warm up by just trying a simple least squares classifier. What is the test accuracy of a least squares classifier trained on this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "w = np.linalg.lstsq(augment(X_train), y_train)[0]\n",
    "y_pred = augment(X_test) @ w\n",
    "(np.sign(y_pred) == y_test).mean()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 02**. Perform k-means clustering and find 100 cluster centers in the training data. Plot a few of the cluster centers using `show_digit` to see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=100)\n",
    "kmeans.fit(X_train)\n",
    "show_digit(kmeans.cluster_centers_[50])\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize first 10 centers\n",
    "for i in range(10):\n",
    "    show_digit(kmeans.cluster_centers_[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 03**. Below is a function which makes a Gaussian RBF given a center $\\mu$ and a value of $\\sigma$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rbf(mu, sigma):\n",
    "    def rbf(x):\n",
    "        return np.exp(-np.linalg.norm(x - mu, axis=1)**2 / sigma**2)\n",
    "    return rbf\n",
    "\n",
    "def rbf_feature(x, mu, sigma):\n",
    "    return np.exp(-np.linalg.norm(x - mu, axis=1)**2 / sigma**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, the function that is created will take in an entire data matrix, $X$, and return an array of the new feature for each data point.\n",
    "\n",
    "Using the k-means cluster centers, create an $n \\times 100$ array `X_phi_train` containing the new RBF features. Choose $\\sigma$ to be something you think is reasonable -- use the same $\\sigma$ for each RBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "rbfs = [make_rbf(mu, 1000) for mu in kmeans.cluster_centers_]\n",
    "X_phi_train = np.column_stack([rbf(X_train) for rbf in rbfs])\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 04**. Following the same procedure, create the array `X_phi_test` which contains the features for the test data mapped to the same representation using the RBFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_phi_test = np.column_stack([rbf(X_test) for rbf in rbfs]) # SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 05**. What is the test accuracy of a least squares classifier training on your new features?\n",
    "\n",
    "*Hint*: You should be able to do better than the least squares classifier we trained before, but *only* if you choose $\\sigma$ correctly. Try a few different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "w = np.linalg.lstsq(augment(X_phi_train), y_train)[0]\n",
    "y_pred = augment(X_phi_test) @ w\n",
    "(np.sign(y_pred) == y_test).mean()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra Question**. In practice, we don't choose $\\sigma$ by hand. Instead, we use a separate *validation* data set to test the accuracy obtained by using a variety of $\\sigma$ and keep the one that returns the best performance. Note that we shouldn't pick the $\\sigma$ that gives us the best result on the test set, because that is cheating!\n",
    "\n",
    "The code below splits our training set into a new training set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = sklearn.model_selection.train_test_split(\n",
    "    X_train, y_train, test_size=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a value of $\\sigma$ which gives the best accuracy on the validation set by looping over possible $\\sigma$ within a reasonable range of possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "def validation_accuracy(sigma):\n",
    "    rbfs = [make_rbf(mu, sigma) for mu in kmeans.cluster_centers_]\n",
    "    X_phi_train = np.column_stack([rbf(X_train) for rbf in rbfs])\n",
    "    X_phi_validation = np.column_stack([rbf(X_validation) for rbf in rbfs])\n",
    "    w = np.linalg.lstsq(augment(X_phi_train), y_train)[0]\n",
    "    y_pred = augment(X_phi_validation) @ w\n",
    "    return (np.sign(y_pred) == y_validation).mean()\n",
    "\n",
    "accs = [(sigma, validation_accuracy(sigma)) for sigma in np.linspace(500, 5000, 20)]\n",
    "accs\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 02**. Consider the data set below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "np.random.seed(42)\n",
    "X_moons, y_moons = sklearn.datasets.make_moons(200, noise=.1)\n",
    "y_moons = (y_moons - .5) * 2\n",
    "\n",
    "plt.scatter(*X_moons.T, c=y_moons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `X_moons` represents a training set of points in $\\mathbb R^2$, containing one data point per row. `y_moons` contains the label of each training point.\n",
    "\n",
    "Design four basis functions, $\\varphi_1, \\ldots, \\varphi_4$ for transforming this data into a new representation in $\\mathbb R^4$ where binary classification becomes \"easy\". Your functions should take in the entire data matrix, `X`, and return an array containing the new feature for each training point.\n",
    "\n",
    "Your basis functions will be evaluated by training a least squares classifier on the augmented new features. To receive full credit, your new representation should be good enough that the classifier has a training accuracy of at least 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "def phi_1(X):\n",
    "    return np.exp(-np.sum((X - [0, -.5])**2, axis=1))\n",
    "\n",
    "def phi_2(X):\n",
    "    return np.exp(-np.sum((X - [2, -.5])**2, axis=1))\n",
    "\n",
    "def phi_3(X):\n",
    "    return np.exp(-np.sum((X - [-1, 1.25])**2, axis=1))\n",
    "\n",
    "def phi_4(X):\n",
    "    return np.exp(-np.sum((X - [1, 1.25])**2, axis=1))\n",
    "\n",
    "Phi = np.column_stack((\n",
    "    np.ones(len(X_moons)),\n",
    "    phi_1(X_moons),\n",
    "    phi_2(X_moons),\n",
    "    phi_3(X_moons),\n",
    "    phi_4(X_moons)\n",
    "))\n",
    "w = np.linalg.solve(Phi.T @ Phi, Phi.T @ y_moons)\n",
    "(np.sign(Phi @ w) == y_moons).mean()\n",
    "\n",
    "\n",
    "# Visualize 2 components of the data in the new representation\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# transformed = pca.fit_transform(Phi)\n",
    "# plt.scatter(*transformed.T, c=y_moons)\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
